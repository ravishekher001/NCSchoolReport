{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 478 entries, 0 to 477\n",
      "Columns: 294 entries, Unnamed: 0 to Percent GLP\n",
      "dtypes: bool(8), float64(264), int64(9), object(13)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "# The normal imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# Import the stats library\n",
    "from scipy import stats\n",
    "\n",
    "# These are the plottinglibraries we'll use:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import seaborn as sns\n",
    "\n",
    "# Command for plots to appear in the iPython Notebook\n",
    "%matplotlib inline\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Starting with the dataset that Dr.Drew helped clean.->highschools saved to .cvs file from graduations rates (2) notebook\n",
    "wd = os.getcwd() #get working directory\n",
    "highschools = pd.read_csv(wd+'\\\\data\\\\highschools.csv', low_memory=False)\n",
    "highschools.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Understanding [10]\n",
    "\n",
    "Describe the purpose of the data set you selected (i.e., why was this data collected in the first place?). Describe how you would define and measure the outcomes from the dataset. That is, why is this data important and how do you know if you have mined useful knowledge from the dataset? \n",
    "How would you measure the effectiveness of a good prediction algorithm? Be specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Meaning Type  [10]\n",
    "\n",
    "Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality [15]\n",
    "\n",
    "Verify data quality: Explain any missing values, duplicate data, and outliers. Are those mistakes? How do you deal with these problems? Give justifications for your methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478, 294)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get dimensions of the dataframe that we working with\n",
    "highschools.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make a copy of the dataset to work with\n",
    "HighschoolData = highschools.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Missing Data Statistics*\n",
    "\n",
    "In this section we explore missing data in the highschool data that was created from the original north carolina data. After exploring the missing data we will discusss the approach for handling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "###              Stats on missing data         ###\n",
      "##################################################\n",
      "No of rows in HighschoolData:  478\n",
      "No of Columns in HighschoolData:  294\n",
      "No. of Columns with Missing data:  168\n",
      "No  of Complete data columns:  126\n",
      "No. of Columns with 100% missing Values:  47\n",
      "No. of Columns more than 95% missing Values:  99\n",
      "% of Columns with some Missing data:  57.143 %\n",
      "% of Columns with 100% Missing data:  15.986 %\n",
      "% of Columns with more than 95% Missing data:  33.673 %\n",
      " \n",
      "##################################################\n",
      "###        Columns with >95% missing data      ###\n",
      "##################################################\n",
      "    DataMissing                ColumnName   Missing %\n",
      "0   478          Percent GLP               100.000000\n",
      "1   478          total_expense_num         100.000000\n",
      "2   478          GCE_RPF_State_Pct         100.000000\n",
      "3   478          GCE_PRM_State_Pct         100.000000\n",
      "4   478          GCE_LEP_State_Pct         100.000000\n",
      "5   478          PASSED_RTA_Dist_Pct       100.000000\n",
      "6   478          GCE_PRM_Dist_Pct          100.000000\n",
      "7   478          GCE_LEP_Dist_Pct          100.000000\n",
      "8   478          RETAINED_School_Pct       100.000000\n",
      "9   478          PASSED_RTA_School_Pct     100.000000\n",
      "10  478          PASSED_LAA_School_Pct     100.000000\n",
      "11  478          salary_expense_pct        100.000000\n",
      "12  478          GCE_LEP_School_Pct        100.000000\n",
      "13  478          benefits_expense_pct      100.000000\n",
      "14  478          services_expense_pct      100.000000\n",
      "15  478          supplies_expense_pct      100.000000\n",
      "16  478          instruct_equip_exp_pct    100.000000\n",
      "17  478          other_expense_pct         100.000000\n",
      "18  478          federal_perpupil_num      100.000000\n",
      "19  478          local_perpupil_num        100.000000\n",
      "20  478          state_perpupil_num        100.000000\n",
      "21  478          GCE_RPF_School_Pct        100.000000\n",
      "22  478          PASSED_RTA_State_Pct      100.000000\n",
      "23  478          esea_attendance           100.000000\n",
      "24  478          lea_esea_attendance       100.000000\n",
      "25  478          lea_ib_participation_pct  100.000000\n",
      "26  478          Percent CCR               100.000000\n",
      "27  478          Percent Level 5           100.000000\n",
      "28  478          Percent Level 4           100.000000\n",
      "29  478          Percent Level 3           100.000000\n",
      "..  ...                      ...                  ...\n",
      "70  475          Avg_Class_Size_03         99.372385 \n",
      "71  475          Avg_Class_Size_02         99.372385 \n",
      "72  474          GCE_ALL_State_Pct         99.163180 \n",
      "73  474          GCE_SWD_State_Pct         99.163180 \n",
      "74  474          PASSED_EOG_State_Pct      99.163180 \n",
      "75  474          PASSED_EOG_Dist_Pct       99.163180 \n",
      "76  474          PROMOTED_Dist_Pct         99.163180 \n",
      "77  474          GCE_ALL_Dist_Pct          99.163180 \n",
      "78  474          PROMOTED_State_Pct        99.163180 \n",
      "79  474          RETAINED_State_Pct        99.163180 \n",
      "80  474          GCE_ALL_School_Pct        99.163180 \n",
      "81  474          PASSED_LAA_State_Pct      99.163180 \n",
      "82  472          ib_participation_pct      98.744770 \n",
      "83  466          Avg_State_Size_06         97.489540 \n",
      "84  466          Avg_Dist_Size_06          97.489540 \n",
      "85  466          Avg_Class_Size_06         97.489540 \n",
      "86  465          Avg_State_Size_08         97.280335 \n",
      "87  465          Avg_State_Size_07         97.280335 \n",
      "88  465          Avg_Dist_Size_08          97.280335 \n",
      "89  465          Avg_Dist_Size_07          97.280335 \n",
      "90  465          Avg_Class_Size_08         97.280335 \n",
      "91  465          Avg_Class_Size_07         97.280335 \n",
      "92  460          Math SPG Score            96.234310 \n",
      "93  460          Math SPG Grade            96.234310 \n",
      "94  460          Reading  SPG Score        96.234310 \n",
      "95  460          Read Score                96.234310 \n",
      "96  460          Math Score                96.234310 \n",
      "97  460          Science Score             96.234310 \n",
      "98  460          Reading SPG Grade         96.234310 \n",
      "99  454          ib_pct_4_or_above         94.979079 \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Check for missing values\n",
    "Temp = pd.DataFrame(HighschoolData.isnull().sum())\n",
    "#print(Temp)\n",
    "Temp.columns =['DataMissing']\n",
    "#Columns with atleast 1 missing value\n",
    "MissingCount = Temp[Temp.DataMissing>0]\n",
    "\n",
    "#sort \n",
    "MissingCount = MissingCount.sort_values('DataMissing',ascending=False)\n",
    "#basic starts on missing data\n",
    "print(\"##################################################\")\n",
    "print(\"###\", '             Stats on missing data        ',  \"###\")\n",
    "print(\"##################################################\")\n",
    "print('No of rows in HighschoolData: ',len(HighschoolData))\n",
    "print('No of Columns in HighschoolData: ',len(HighschoolData.columns))\n",
    "print('No. of Columns with Missing data: ',len(MissingCount))\n",
    "print('No  of Complete data columns: ', len(HighschoolData.columns) - len(MissingCount))\n",
    "print('No. of Columns with 100% missing Values: ',sum(1 for item in MissingCount.DataMissing if item==len(HighschoolData)))\n",
    "print('No. of Columns more than 95% missing Values: ',sum(1 for item in MissingCount.DataMissing if item>=0.95*len(HighschoolData)))\n",
    "print('% of Columns with some Missing data: ',round(float(100*len(MissingCount))/len(HighschoolData.columns),3),'%')\n",
    "print('% of Columns with 100% Missing data: ',round(float(100*sum(1 for item in MissingCount.DataMissing if item==len(HighschoolData)))/len(HighschoolData.columns),3),'%')\n",
    "print('% of Columns with more than 95% Missing data: ',round(float(100*sum(1 for item in MissingCount.DataMissing if item>=0.95*len(HighschoolData)))/len(HighschoolData.columns),3),'%')\n",
    "\n",
    "print(\" \")\n",
    "print(\"##################################################\")\n",
    "print(\"###\",'       Columns with >95% missing data     ',    \"###\")\n",
    "print(\"##################################################\")\n",
    "#add a columnName for Bar charts plot\n",
    "MissingCount['ColumnName'] = MissingCount.index\n",
    "MissingCount['Missing %'] = 100*(MissingCount.DataMissing/len(HighschoolData))\n",
    "MissingCount = MissingCount.reset_index()\n",
    "del MissingCount['index']\n",
    "print((MissingCount.head(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Approach for handling missing data to be discussed with the rest of the team\n",
    "From above we note, of the 293 columns in HighSchoolData, 168 (57.14%) of them have some missing data. 47 (15.99%) of columns have all the data missing where 99 (33.67%) of the columns miss more than 95% of the data. For columns with 100% missing data we are left but to wonder if this were new fields introduced recently and the schools are not fully informed to collect this data or the data for not just collected by mistake. On the other hand, for the partally completed datasets, some schools migh have left this columns blank if they didn't apply to the.\n",
    "\n",
    "For the sake of this analysis we will drop the columns that have `>95` missing data rather than try complete the missing data with either mean, median or mode. If we complete this large amount of columns, with predetermined data, our model maybe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 478 entries, 0 to 477\n",
      "Columns: 255 entries, total_specialized_courses to PASSED_EOG_State_Pct\n",
      "dtypes: bool(8), float64(225), int64(9), object(13)\n",
      "memory usage: 926.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_specialized_courses</th>\n",
       "      <th>Math Score</th>\n",
       "      <th>Reading SPG Grade</th>\n",
       "      <th>lea_wap_num</th>\n",
       "      <th>st_flicensed_teach_pct</th>\n",
       "      <th>st_not_highqual_class_all_pct</th>\n",
       "      <th>PASSED_EOG_School_Pct</th>\n",
       "      <th>tchyrs_0thru3_pct</th>\n",
       "      <th>type_cd_txt</th>\n",
       "      <th>PASSED_LAA_Dist_Pct</th>\n",
       "      <th>...</th>\n",
       "      <th>Avg_Class_Size_05</th>\n",
       "      <th>_1yr_tchr_trnovr_pct</th>\n",
       "      <th>st_highqual_class_hp_pct</th>\n",
       "      <th>Grad_project_status</th>\n",
       "      <th>Math Course Rigor Score</th>\n",
       "      <th>lea_long_susp_per_c_num</th>\n",
       "      <th>Avg_Class_Size_04</th>\n",
       "      <th>st_highqual_class_pct</th>\n",
       "      <th>Avg_Class_Size_03</th>\n",
       "      <th>PASSED_EOG_State_Pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.964</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.186</td>\n",
       "      <td>Public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.964</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_specialized_courses  Math Score Reading SPG Grade  lea_wap_num  \\\n",
       "0 NaN                        NaN          NaN               1380.0        \n",
       "1 NaN                        NaN          NaN               1380.0        \n",
       "\n",
       "   st_flicensed_teach_pct  st_not_highqual_class_all_pct  \\\n",
       "0  0.897                   0.037                           \n",
       "1  0.897                   0.037                           \n",
       "\n",
       "   PASSED_EOG_School_Pct  tchyrs_0thru3_pct type_cd_txt  PASSED_LAA_Dist_Pct  \\\n",
       "0 NaN                     0.000              Public     NaN                    \n",
       "1 NaN                     0.186              Public     NaN                    \n",
       "\n",
       "           ...           Avg_Class_Size_05  _1yr_tchr_trnovr_pct  \\\n",
       "0          ...          NaN                 0.000                  \n",
       "1          ...          NaN                 0.128                  \n",
       "\n",
       "   st_highqual_class_hp_pct  Grad_project_status  Math Course Rigor Score  \\\n",
       "0  0.964                     False               NaN                        \n",
       "1  0.964                     False               NaN                        \n",
       "\n",
       "   lea_long_susp_per_c_num  Avg_Class_Size_04  st_highqual_class_pct  \\\n",
       "0  0.23                    NaN                 0.964                   \n",
       "1  0.23                    NaN                 0.964                   \n",
       "\n",
       "   Avg_Class_Size_03  PASSED_EOG_State_Pct  \n",
       "0 NaN                NaN                    \n",
       "1 NaN                NaN                    \n",
       "\n",
       "[2 rows x 255 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All columns from Original schoolData\n",
    "AllColumns =HighschoolData.columns \n",
    "\n",
    "# All columns with some missing value\n",
    "ColumnsWithMissingdata = MissingCount.ColumnName \n",
    "\n",
    "#columns with more than 95% missing data\n",
    "Columns2Drop = MissingCount.ColumnName.head(39) \n",
    "\n",
    "#columns with missing values that are kept\n",
    "Columns2Keep = MissingCount.ColumnName.tail(len(MissingCount)-39) \n",
    "\n",
    "#All the other columns except those with >95% missing data\n",
    "SelectedColumns = list(set(AllColumns)-set(Columns2Drop)) \n",
    "\n",
    "#new dataset, columns with >95% missing data dropped\n",
    "\n",
    "schoolDataNew = HighschoolData[SelectedColumns]\n",
    "\n",
    "## Peek at New Dataframe\n",
    "print(HighschoolData)\n",
    "print(schoolDataNew.info())\n",
    "schoolDataNew.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Statistics [10]\n",
    "Visualize appropriate statistics (e.g., range, mode, mean, median, variance, counts) for a subset of attributes. Describe anything meaningful you found from this or if you found something potentially interesting. Note: You can also use data from other sources for comparison. Explain why the statistics run are meaningful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Attributes [15]\n",
    "Visualize the most interesting attributes (at least 5 attributes, your opinion on what is interesting). Important: Interpret the implications for each visualization. Explain for each attribute why the chosen visualization is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Joint Attributes [15]\n",
    "Visualize relationships between attributes: Look at the attributes via scatter plots, correlation, cross-tabulation, group-wise averages, etc. as appropriate. Explain any interesting relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Features [5]\n",
    "Are there other features that could be added to the data or created from existing features? Which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exceptional Work [10]\n",
    "You have free reign to provide additional analyses. One idea: implement dimensionality reduction, then visualize and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Dictionary\n",
    "Since this datasets has numerous columns we needed a fast way to quickly find ColumnName description for easy reference. For exceptional work, we created a function to quickly pull the data from csv datafile. This involved converting the pdf to excel and formating the data for easy import into pandas. The code below is a working code for our data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter column name to check description in Dictionary. You can enter multiple columns separated by comma: A, T, M, I, E\n",
      "You entered:  A, T, M, I, E\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COLUMN_NAME</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>a</td>\n",
       "      <td>School has elementary, middle, and high school grades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>t</td>\n",
       "      <td>School has middle and high school grades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>m</td>\n",
       "      <td>School has middle schools grades (6-8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>i</td>\n",
       "      <td>School has elementary and middle school grades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>e</td>\n",
       "      <td>School has elementary schools grades (PK-5)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COLUMN_NAME                                            DESCRIPTION\n",
       "373  a           School has elementary, middle, and high school grades\n",
       "372  t           School has middle and high school grades             \n",
       "369  m           School has middle schools grades (6-8)               \n",
       "371  i           School has elementary and middle school grades       \n",
       "368  e           School has elementary schools grades (PK-5)          "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a simple function to pull column description\n",
    "DataDict = pd.read_csv(wd+'\\\\data\\\\dictionary.csv', encoding = \"ISO-8859-1\")\n",
    "DataDict.head()\n",
    "#DataDict = DataDict.columns['COLUMN_NAME', 'DESCRIPTION']\n",
    "def get_ColDescription(colname = 'Year'):\n",
    "    colName = input(\"Enter column name to check description in Dictionary. You can enter multiple columns separated by comma: \")\n",
    "    \n",
    "    print('You entered: ', colName.strip())\n",
    "    temp = pd.DataFrame()\n",
    "    colNames = colName.split(',')\n",
    "    \n",
    "    try:\n",
    "        for i in range(0,len(colNames)):\n",
    "            get = (DataDict[DataDict.COLUMN_NAME==colNames[i].strip().lower()])\n",
    "            temp = temp.append(get)\n",
    "        return(temp)\n",
    "    except Exception as e:\n",
    "        print(e.args) \n",
    "\n",
    "get_ColDescription()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
