{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/Users/Shravan/R/projects/NCSchoolReport\\\\data\\\\highschools.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-55cb5df6459a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#get working directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#highschools = pd.read_csv(wd+'/data/highschools.csv', low_memory=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mhighschools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\\\data\\\\highschools.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mhighschools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Shravan/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    644\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Shravan/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Shravan/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Shravan/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Shravan/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:4184)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:8449)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/Users/Shravan/R/projects/NCSchoolReport\\\\data\\\\highschools.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "# The normal imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# Import the stats library\n",
    "from scipy import stats\n",
    "\n",
    "# These are the plottinglibraries we'll use:\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "plt.style.use(\"classic\")\n",
    "import seaborn as sns\n",
    "\n",
    "#Machine learning\n",
    "\n",
    "\n",
    "# Command for plots to appear in the iPython Notebook\n",
    "%matplotlib inline\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Starting with the dataset that Dr.Drew helped clean.->highschools saved to .cvs file from graduations rates (2) notebook\n",
    "wd = os.getcwd() #get working directory\n",
    "highschools = pd.read_csv(wd+'/data/highschools.csv', low_memory=False)\n",
    "#highschools = pd.read_csv(wd+'\\\\data\\\\highschools.csv', low_memory=False)\n",
    "highschools.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business Understanding [10]\n",
    "\n",
    "Describe the purpose of the data set you selected (i.e., why was this data collected in the first place?). Describe how you would define and measure the outcomes from the dataset. That is, why is this data important and how do you know if you have mined useful knowledge from the dataset? \n",
    "How would you measure the effectiveness of a good prediction algorithm? Be specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Meaning Type  [10]\n",
    "\n",
    "Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality [15]\n",
    "\n",
    "Verify data quality: Explain any missing values, duplicate data, and outliers. Are those mistakes? How do you deal with these problems? Give justifications for your methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get dimensions of the dataframe that we working with\n",
    "highschools.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make a copy of the dataset to work with\n",
    "HighschoolData = highschools.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Missing Data Statistics*\n",
    "\n",
    "In this section we explore missing data in the highschool data that was created from the original north carolina data. After exploring the missing data we will discusss the approach for handling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check for missing values\n",
    "Temp = pd.DataFrame(HighschoolData.isnull().sum())\n",
    "#print(Temp)\n",
    "Temp.columns =['DataMissing']\n",
    "#Columns with atleast 1 missing value\n",
    "MissingCount = Temp[Temp.DataMissing>0]\n",
    "\n",
    "#sort \n",
    "MissingCount = MissingCount.sort_values('DataMissing',ascending=False)\n",
    "#basic starts on missing data\n",
    "print(\"##################################################\")\n",
    "print(\"###\", '             Stats on missing data        ',  \"###\")\n",
    "print(\"##################################################\")\n",
    "print('No of rows in HighschoolData: ',len(HighschoolData))\n",
    "print('No of Columns in HighschoolData: ',len(HighschoolData.columns))\n",
    "print('No. of Columns with Missing data: ',len(MissingCount))\n",
    "print('No  of Complete data columns: ', len(HighschoolData.columns) - len(MissingCount))\n",
    "print('No. of Columns with 100% missing Values: ',sum(1 for item in MissingCount.DataMissing if item==len(HighschoolData)))\n",
    "print('No. of Columns more than 95% missing Values: ',sum(1 for item in MissingCount.DataMissing if item>=0.95*len(HighschoolData)))\n",
    "print('% of Columns with some Missing data: ',round(float(100*len(MissingCount))/len(HighschoolData.columns),3),'%')\n",
    "print('% of Columns with 100% Missing data: ',round(float(100*sum(1 for item in MissingCount.DataMissing if item==len(HighschoolData)))/len(HighschoolData.columns),3),'%')\n",
    "print('% of Columns with more than 95% Missing data: ',round(float(100*sum(1 for item in MissingCount.DataMissing if item>=0.95*len(HighschoolData)))/len(HighschoolData.columns),3),'%')\n",
    "\n",
    "print(\" \")\n",
    "print(\"##################################################\")\n",
    "print(\"###\",'       Columns with >95% missing data     ',    \"###\")\n",
    "print(\"##################################################\")\n",
    "#add a columnName for Bar charts plot\n",
    "MissingCount['ColumnName'] = MissingCount.index\n",
    "MissingCount['Missing %'] = 100*(MissingCount.DataMissing/len(HighschoolData))\n",
    "MissingCount = MissingCount.reset_index()\n",
    "del MissingCount['index']\n",
    "print((MissingCount.head(100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we note, of the 293 columns in HighSchoolData, 168 (57.14%) of them have some missing data. 47 (15.99%) of columns have all the data missing where 99 (33.67%) of the columns miss more than 95% of the data. For columns with 100% missing data we are left but to wonder if this were new fields introduced recently and the schools are not fully informed to collect this data or the data for not just collected by mistake. On the other hand, for the partally completed datasets, some schools migh have left this columns blank if they didn't apply to the.\n",
    "\n",
    "For the sake of this analysis we will drop the columns that have `>95` missing data rather than try complete the missing data with either mean, median or mode. If we complete this large amount of columns, with predetermined data, our model maybe baised and throw us off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#All columns from Original schoolData\n",
    "AllColumns =HighschoolData.columns \n",
    "\n",
    "# All columns with some missing value\n",
    "ColumnsWithMissingdata = MissingCount.ColumnName \n",
    "\n",
    "#columns with more than 95% missing data\n",
    "Columns2Drop = MissingCount.ColumnName.head(99) \n",
    "\n",
    "#columns with missing values that are kept\n",
    "Columns2Keep = MissingCount.ColumnName.tail(len(MissingCount)-99) \n",
    "\n",
    "#All the other columns except those with >95% missing data\n",
    "SelectedColumns = list(set(AllColumns)-set(Columns2Drop)) \n",
    "\n",
    "#new dataset, columns with >95% missing data dropped\n",
    "\n",
    "schoolDataNew = HighschoolData[SelectedColumns]\n",
    "\n",
    "print(\"##################################################\")\n",
    "print(\"###\", '          Orginal Highschooldata info     ',  \"###\")\n",
    "print(\"##################################################\")\n",
    "print(HighschoolData.info())\n",
    "print(\"##################################################\")\n",
    "print(\"###\", '  Columns with >95 data missing   dropped ',  \"###\")\n",
    "print(\"##################################################\")\n",
    "print(schoolDataNew.info())\n",
    "schoolDataNew.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code block above, we drop 99 columns which have >95% of the data missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Exploring the columns with missing dataset that are retained\n",
    "df = schoolDataNew[Columns2Keep]\n",
    "temp_df = df.copy() \n",
    "print(\"##################################################\")\n",
    "temp  = df.select_dtypes(include=['int','float'])\n",
    "temp2  = df.select_dtypes(include=['object', 'bool'])\n",
    "print(\"#      Columns with continious data (int, float) #\")\n",
    "print(\"##################################################\")\n",
    "temp.info()\n",
    "print(\" \")\n",
    "print(\"##########################################\")\n",
    "print(\"#     Columns with Categorical data      #\")\n",
    "print(\"##########################################\")\n",
    "temp2.info()\n",
    "print(\" \")\n",
    "print(\"Total # of columns: \",len(Columns2Keep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code block above we explore the columns with missing data that we retained. we group the columns into two based on data type as we will have two different approaches for replacing the missing data;\n",
    "1. #### Columns with continuous data types (ints and floats)\n",
    "Of the 69 columns retained with missing data, 64 are of dtype float64. After reviewing individual columns description from the data dictionary, We choose to replacing this missing float types with median. We didn't go with mean simply because with existance of outliers, mean would be screwed compared to median.\n",
    "2. #### Columns with contegorical data types (objects)\n",
    "For the 5 categorical values we will replacing the missing values with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#this function replaces NA's for columns with continous 'Con' (int or float) variables with median and categorical 'Cat' variable(bool or object) with mode\n",
    "def ReplaceMissingdata(df = schoolDataNew):\n",
    "    temp_df = df.copy() \n",
    "    print(\"#######################################\")\n",
    "    print(\"## continous and categorical columns ##\")\n",
    "    print(\"#######################################\")\n",
    "    temp  = df.select_dtypes(include=['int64','float'])    #continuous values columns\n",
    "    columnnames = temp.columns\n",
    "    temp1  = df.select_dtypes(include=['object','bool']) #catagorical values columns\n",
    "    columnnames1 = temp1.columns\n",
    "    print(\" \")\n",
    "    \n",
    "    print(\"##############################\")\n",
    "    print(\"## NA count Before Cleaning ##\")\n",
    "    print(\"##############################\")\n",
    "    print(df.isnull().sum())\n",
    "    #replacing missing continous values with median\n",
    "    for i in range(0,len(columnnames)):\n",
    "        try:\n",
    "            temp_array =temp[temp[columnnames[i]]!=np.nan][columnnames[i]] #temp array of non NAs for continous values to calculate median\n",
    "            # replace NAs with median for continous variables created from above arrays\n",
    "            temp_df[columnnames[i]] =temp_df[columnnames[i]].replace(np.nan,temp_array.median())     \n",
    "        except Exception as e:\n",
    "            print(e.args) \n",
    "            \n",
    "    #replacing missing contegorical values with mode\n",
    "    for i in range(0,len(columnnames1)):\n",
    "        try:\n",
    "            temp_array1 =temp1[temp1[columnnames1[i]]!=np.nan][columnnames1[i]] #temp array of non NAs for categorical values to calculate mode\n",
    "            # replace NAs with median for categorical values created from above arrays with mode\n",
    "            temp_df[columnnames1[i]] =temp_df[columnnames1[i]].replace(np.nan,str(temp_array1.mode()))      \n",
    "        except Exception as e:\n",
    "            print(e.args)\n",
    "\n",
    "    print(\"##############################\")\n",
    "    print(\"## NA Count After Cleaning  ##\")\n",
    "    print(\"##############################\")\n",
    "    print(temp_df.isnull().sum())\n",
    "    df = temp_df\n",
    "    return df\n",
    "\n",
    "new_schooldata = ReplaceMissingdata(schoolDataNew)    \n",
    "\n",
    "new_schooldata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code block above, we replaced missing catagorical values with mode and missing continous values with median. A total of 69 columns with missing values have been cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function for getting column description from the data dictionary. \n",
    "# It is at the bottom of the notebook in the exceptional work section. Run it first before calling it in this cell\n",
    "get_ColDescription()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Statistics [10]\n",
    "Visualize appropriate statistics (e.g., range, mode, mean, median, variance, counts) for a subset of attributes. Describe anything meaningful you found from this or if you found something potentially interesting. Note: You can also use data from other sources for comparison. Explain why the statistics run are meaningful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the `new_schooldata` dataframe going forward for calculating the simple statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a copy of the dataset to work with\n",
    "statsSchoolData = new_schooldata.copy()\n",
    "\n",
    "# Extract Bool, Object and Numeric types into seperate df's\n",
    "statsSchoolDataBool = statsSchoolData.loc[:, statsSchoolData.dtypes == bool]\n",
    "statsSchoolDataObject = statsSchoolData.loc[:, statsSchoolData.dtypes == object]\n",
    "statsSchoolDataNumeric = statsSchoolData.loc[:, (statsSchoolData.dtypes == float) | (statsSchoolData.dtypes == int)]\n",
    "\n",
    "# Remove spaces from column names. Eg: \"State Gap Compared\" becomes \"State_Gap_Compared\"\n",
    "statsSchoolDataObject.columns = statsSchoolDataObject.columns.str.replace('\\s+', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean Variables Simple Stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statsSchoolDataBool.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object Variables Simple Stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "statsSchoolDataObject.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numeric Variables Simple Stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(statsSchoolDataNumeric.describe(include='all').T).round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: \n",
    "- Write about the observations from these simple stats\n",
    "- Try to calculate outliers for numeric variables and add a new column called Outlier with True/False value.\n",
    "- Fix the issue with Object type categorical variables. They have a `0 N\\ndtype: object` value. This should be renamed to `Unknown` category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple visualization of the boolean variables. (We can remove this later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(statsSchoolDataBool.columns)):\n",
    "    plt.figure(figsize=(20,5))\n",
    "    statsSchoolDataBool.iloc[:,i].value_counts().plot(kind=\"barh\")\n",
    "    plt.title(statsSchoolDataBool.iloc[:,i].name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Attributes [15]\n",
    "Visualize the most interesting attributes (at least 5 attributes, your opinion on what is interesting). Important: Interpret the implications for each visualization. Explain for each attribute why the chosen visualization is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# School Category Factor plot \n",
    "fig, ax = plt.subplots(figsize=(16, 7))\n",
    "sns.countplot(\"category_cd\",data=new_schooldata)\n",
    "new_schooldata.groupby([\"category_cd\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the 478 High schools, 459 are of fall in  category H ,15 of catagory T and 4 of category A. Please reference the table below for school category descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_ColDescription()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#histograms of teacher experience\n",
    "#with sns.axes_style(\"darkgrid\"):\n",
    "X =new_schooldata.Tch_Exp_Pct_0_3_Years\n",
    "Y  =new_schooldata.Tch_Exp_Pct_4_10_Years\n",
    "Z =new_schooldata[\"Tch_Exp_Pct_10+_Years\"]\n",
    "fig, ax = plt.subplots(figsize=(13, 6))\n",
    "bins = 70\n",
    "figure_title = \"Histogram of % of Teachers at a given experience Level at High Schools in NC\"\n",
    "plt.title(figure_title, y=1.08)\n",
    "plt.hist(X, bins, alpha=0.7, label='0-3 Years')\n",
    "plt.hist(Y, bins, alpha=0.7, label='4-10 Years')\n",
    "plt.hist(Z, bins, alpha=0.7, label='+10 Years')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TO be updated.\n",
    "From Histogram above, majority of schools in NC have high percentage of teachers with over 10 years of experience. There is little difference in distributions of percentages of teachers with 0-3 years and 4 to 10 years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "A =new_schooldata.avg_daily_attend_pct\n",
    "fig, ax = plt.subplots(figsize=(13, 6))\n",
    "bins = 70\n",
    "plt.hist(A, bins, alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_ColDescription()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Joint Attributes [15]\n",
    "Visualize relationships between attributes: Look at the attributes via scatter plots, correlation, cross-tabulation, group-wise averages, etc. as appropriate. Explain any interesting relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. School Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Categorical columns for joint plots explorations\n",
    "temp = new_schooldata.select_dtypes(['bool','object'])\n",
    "\n",
    "#store the selected columns list in array\n",
    "categorical_cols = temp.columns\n",
    "print('Categorical columns')\n",
    "print('-------------------------------')\n",
    "print(categorical_cols)\n",
    "\n",
    "print('-------------------------------')\n",
    "print('')\n",
    "print('-------------------------------')\n",
    "print('Educator Experience')\n",
    "#list of columns for teacher experience measures\n",
    "teacher = [col for col in new_schooldata.columns if 'Tch' in col]\n",
    "Teacher = [teacher[1], teacher[2],teacher[6]]\n",
    "print(Teacher)\n",
    "print('-------------------------------')\n",
    "print('')\n",
    "print('-------------------------------')\n",
    "#List of Columns for achivement score measures\n",
    "#Achivement_measures  = ['The ACT Score','Overall Achievement Score','sch_percent_college_enrolled_16_mos_post_grad','EVAAS Growth Score','Math Course Rigor Score','sat_avg_score_num','Cohort Graduation Rate Standard Score']\n",
    "Achievement_scores = [col for col in new_schooldata.columns if 'score' in col]\n",
    "Achievement_Scores = [col for col in new_schooldata.columns if 'Score' in col]\n",
    "\n",
    "#combine the above two arrays\n",
    "Achievement_measures = Achievement_Scores+Achievement_scores \n",
    "print('Achievement Measures columns')\n",
    "print('-------------------------------')\n",
    "Achievement_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# factor plots for scores vs teacher experience considering categorical factors\n",
    "for i in range(0, len(Achievement_measures)):\n",
    "    sns.factorplot('category_cd',Achievement_measures[i],hue='summer_program_flg',data=new_schooldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sort the x-axis (catagory_cd) from above\n",
    "with sns.axes_style(\"darkgrid\"):\n",
    "    new_schooldata2=new_schooldata.sort_values(axis =0, by='category_cd')\n",
    "    for i in range(0, len(Achievement_measures)):\n",
    "        sns.factorplot('category_cd',Achievement_measures[i],data=new_schooldata2, size = 6, aspect=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sns.set_style(\"dark\")\n",
    "with sns.axes_style(\"darkgrid\"):\n",
    "    sns.factorplot('category_cd','The ACT Score',data=new_schooldata2,size=5, aspect=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above three code blocks, a strong correlation exists between School catagory_cd and its performance in the different performance and test scores measures.Considering Math Score,The ACT Score, Biology Score, EVAAS Growth Score and cohort Graduation Rate Standard score, schools category  A (Schools with elementary, middle and high school grades) performed much better followed by category H (Schools with high school grades 9-13) then Schools T (schools with middle and high school grades). We show one plot for ACT which displays the trend being described. Since the number of Schools of category A=4  and T=15 are less than the 30 samples, though a posible trend exists, we do not draw a statistical conclusion on performance based on school catagory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(Teacher)):\n",
    "    for j in range(0, len(Achievement_measures)):\n",
    "        sns.jointplot(new_schooldata2[Teacher[i]], new_schooldata2[Achievement_measures[j]], size=10, kind ='reg')\n",
    "\n",
    "    #sns.factorplot('category_cd',Teacher[i],data=new_schooldata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#finding a list of the most correlate features\n",
    "c = new_schooldata.corr().abs()\n",
    "s =pd.DataFrame(c.unstack())\n",
    "#so = s.order(kind=\"quicksort\")\n",
    "s['Correlation Pair'] = s.index\n",
    "s = s.reset_index()\n",
    "#del s['index']\n",
    "s.columns = ['Column1', 'Column2', 'correlation','Correlation Pair']\n",
    "result = s.sort_values('correlation', ascending=0)\n",
    "result2 = result[ result.correlation<1]\n",
    "result3 = result2[result2.correlation>0.6]\n",
    "result4 = result3.iloc[::2] # drop alt rows which are duplicate Corr\n",
    "result4[result4.Column1.isin(Achievement_measures)]\n",
    "#result3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through correlation calculation, as could have been expected, there exists a strong correlation between standardized tests.. Though one could have expected perfomance in tests to be strongly correlated to attendance, Average daily attendance 'avg_daily_attend_pct' shows up with a moderate correlation of 0.62 to The ACT Score and 0.61 to English II Score  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Attributes and Class [10]\n",
    "Identify and explain interesting relationships between features and the class you are trying to predict (i.e., relationships with variables and the target classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Features [5]\n",
    "Are there other features that could be added to the data or created from existing features? Which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create Factors for 'Overall Achievement Score'\n",
    "# A: >85\n",
    "# B: 70-85\n",
    "# C: 50-70\n",
    "# D: <50\n",
    "\n",
    "new_schooldata['Overall Achievement Score'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exceptional Work [10]\n",
    "You have free reign to provide additional analyses. One idea: implement dimensionality reduction, then visualize and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Dictionary\n",
    "Since this datasets has numerous columns we needed a fast way to quickly find ColumnName description for easy reference. For exceptional work, we created a function to quickly pull the data from csv datafile. This involved converting the pdf to excel and formating the data for easy import into pandas. The code below is a working code for our data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is a simple function to pull column description\n",
    "DataDict = pd.read_csv(wd+'\\\\data\\\\dictionary.csv', encoding = \"ISO-8859-1\")\n",
    "DataDict.head()\n",
    "#DataDict = DataDict.columns['COLUMN_NAME', 'DESCRIPTION']\n",
    "def get_ColDescription(colname = 'Year'):\n",
    "    colName = input(\"Enter column name to check description in Dictionary. You can enter multiple columns separated by comma: \")\n",
    "    \n",
    "    print('You entered: ', colName.strip())\n",
    "    temp = pd.DataFrame()\n",
    "    colNames = colName.split(',')\n",
    "    \n",
    "    try:\n",
    "        for i in range(0,len(colNames)):\n",
    "            get = (DataDict[DataDict.COLUMN_NAME==colNames[i].strip().lower()])\n",
    "            temp = temp.append(get)\n",
    "        return(temp)\n",
    "    except Exception as e:\n",
    "        print(e.args) \n",
    "\n",
    "get_ColDescription()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# embedding Image\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(url='https://public.tableau.com/en-us/s/gallery/life-hashtag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
